{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nExample of LSE KeOps reduction using the generic syntax. \n==========================================================\n\nThis example uses the pyTorch framework.\n\n# this example computes the following tensor operation :\n# inputs :\n#   x   : a 3000x1 tensor, with entries denoted x_i^u\n#   y   : a 5000x1 tensor, with entries denoted y_j^u\n#   a   : a 5000x1 tensor, with entries denoted a_j\n#   p   : a scalar (entered as a 1x1 tensor)\n# output :\n#   c   : a 3000x3 tensor, with entries denoted c_i^u, such that\n#   c_i^u = sum_j (p-a_j)^2 exp(x_i^u+y_j^u)\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#--------------------------------------------------------------#\n#                     Standard imports                         #\n#--------------------------------------------------------------#\nimport time\nimport torch\nfrom torch.autograd import grad\n\n\n#--------------------------------------------------------------#\n#   Please use the \"verbose\" compilation mode for debugging    #\n#--------------------------------------------------------------#\n#import sys, os.path\n#sys.path.append(os.path.dirname(os.path.abspath(__file__)) + (os.path.sep + '..')*2)\n\nfrom pykeops.torch import Genred\n\n# import pykeops\n# pykeops.verbose = False\n\n#--------------------------------------------------------------#\n#                   Define our dataset                         #\n#--------------------------------------------------------------#\nM = 3000\nN = 5000\n\ntype = 'float32' # Could be 'float32' or 'float64'\ntorchtype = torch.float32 if type == 'float32' else torch.float64\n\nx = torch.rand(M, 1, dtype=torchtype)\ny = torch.rand(N, 1, dtype=torchtype, requires_grad=True)\na = torch.rand(N, 1, dtype=torchtype)\np = torch.rand(1, 1, dtype=torchtype)\n\n#--------------------------------------------------------------#\n#                        Kernel                                #\n#--------------------------------------------------------------#\nformula = 'Square(p-a)*Exp(x+y)'\nvariables = ['x = Vx(1)',  # First arg   : i-variable, of size 3\n             'y = Vy(1)',  # Second arg  : j-variable, of size 3\n             'a = Vy(1)',  # Third arg   : j-variable, of size 1 (scalar)\n             'p = Pm(1)']  # Fourth  arg : Parameter,  of size 1 (scalar)\n         \nstart = time.time()\n\n# The parameter reduction_op='LogSumExp' together with axis=1 means that the reduction operation\n# is a log-sum-exp over the second dimension j. Thence the results will be an i-variable.\nmy_routine = Genred(formula, variables, reduction_op='LogSumExp', axis=1, cuda_type=type)\ntmp = my_routine(x, y, a, p, backend='CPU')\n# in fact the log-sum-exp operation in Keops computes pairs (m,s) such that the LSE is m+log(s)\nc = tmp[:,0] + torch.log(tmp[:,1])\n\n# N.B.: By specifying backend='CPU', we make sure that the result is computed\n#       using a simple C++ for loop.\nprint('Time to compute the convolution operation on the cpu: ', round(time.time()-start,5), 's', end=' ')\n\n\n# We compare with Log of Sum of Exp :\nmy_routine2 = Genred('Exp('+formula+')', variables, reduction_op='Sum', axis=1, cuda_type=type)\nc2 = torch.log(my_routine2(x, y, a, p, backend='CPU'))[:,0]\nprint('(relative error: ',((c2-c).norm()/c.norm()).item(), ')')\n\n#--------------------------------------------------------------#\n#                        Gradient                              #\n#--------------------------------------------------------------#\n# Now, let's compute the gradient of \"c\" with respect to y. \n# Note that since \"c\" is not scalar valued, its \"gradient\" should be understood as \n# the adjoint of the differential operator, i.e. as the linear operator that takes as input \n# a new tensor \"e\" with same size as \"c\" and outputs a tensor \"g\" with same size as \"y\"\n# such that for all variation \u03b4y of y :\n#    < dc.\u03b4y , e >_2  =  < g , \u03b4y >_2  =  < \u03b4y , dc*.e >_2\n\n# New variable of size Mx1 used as input of the gradient\ne = torch.rand_like(c)\n# Call the gradient op:\nstart = time.time()\ng = grad(c, y, e)[0]\n# PyTorch remark : grad(c, y, e) alone outputs a length 1 tuple, hence the need for [0] at the end.\n\nprint('Time to compute gradient of convolution operation on the cpu: ', round(time.time()-start,5), 's', end=' ')\n\n# We compare with gradient of Log of Sum of Exp :\ng2 = grad(c2, y, e)[0]\nprint('(relative error: ',((g2-g).norm()/g.norm()).item(), ')')\n\n\n#--------------------------------------------------------------#\n#            same operations performed on the Gpu              #\n#--------------------------------------------------------------#\n# This will of course only work if you have a Gpu...\n\nif torch.cuda.is_available():\n    # first transfer data on gpu\n    pc, ac, xc, yc, ec = p.cuda(), a.cuda(), x.cuda(), y.cuda(), e.cuda()\n    # then call the operations\n    start = time.time()\n    c3 = my_routine(xc, yc, ac, pc, backend='GPU')\n    c3 = c3[:,0] + torch.log(c3[:,1])\n    print('Time to compute convolution operation on gpu:',round(time.time()-start,5), 's ', end='')\n    print('(relative error:', float(torch.abs((c2 - c3.cpu()) / c2).mean()), ')')\n    start = time.time()\n    g3 = grad(c3, yc, ec)[0]\n    print('Time to compute gradient of convolution operation on gpu:', round(time.time()-start,5), 's ', end='')\n    print('(relative error:', float(torch.abs((g2 - g3.cpu()) / g2).mean()), ')')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}