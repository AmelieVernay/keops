{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nUsing variable, anisotropic kernels\n===================================\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#import sys, os.path\n#sys.path.append(os.path.dirname(os.path.abspath(__file__)) + (os.path.sep + '..')*2)\n\n# Standard imports\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport matplotlib.cm as cm\nimport torch\nfrom torch.autograd import grad\nfrom pykeops.torch  import Kernel, kernel_product\n\nplt.ion()\n\n# Choose the storage place for our data : CPU (host) or GPU (device) memory.\ndtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n\n\n# Define our dataset =====================================================================\n# Three points in the plane R^2\ny = torch.tensor( [\n    [ .2, .7],\n    [ .5, .3],\n    [ .7, .5]\n    ]).type(dtype)\n# Three scalar weights\nb = torch.tensor([\n    1., 1., .5\n    ]).type(dtype)\n# Remember : b is not a vector, but a \"list of unidimensional vectors\"!\nb = b.view(-1,1) \n\n# DISPLAY ================================================================================\n# Create a uniform grid on the unit square:\nres = 100\nticks  = np.linspace( 0, 1, res+1)[:-1] + .5 / res \nX,Y    = np.meshgrid( ticks, ticks )\n\n# Beware! By default, numpy uses float64 precision whereas pytorch uses float32.\n# If you don't convert explicitely your data to compatible dtypes,\n# PyTorch or Keops will throw an error.\nx = torch.from_numpy(np.vstack( (X.ravel(), Y.ravel()) ).T).contiguous().type(dtype)\n\ndef showcase_params( params , title, ind) :\n    \"\"\"Samples \"x -> \u2211_j b_j * k_j(x - y_j)\" on the grid, and displays it as a heatmap.\"\"\"\n    heatmap   = kernel_product(params, x, y, b)\n    heatmap   = heatmap.view(res,res).cpu().numpy() # reshape as a \"background\" image\n    \n    plt.subplot(2,3,ind)\n    plt.imshow(  -heatmap, interpolation='bilinear', origin='lower', \n                vmin = -1, vmax = 1, cmap=cm.RdBu, \n                extent=(0,1,0,1)) \n    plt.title(title, fontsize=20)\n\nplt.figure()\n\n# TEST ===================================================================================\n# Let's use a \"gaussian\" kernel, i.e.\n#        k(x_i,y_j) = exp( - WeightedSquareNorm(gamma, x_i-y_j ) )\nparams = {\n    \"id\"      : Kernel(\"gaussian(x,y)\"),\n}\n\n# The type of kernel is inferred from the shape of the parameter \"gamma\",\n# used as a \"metric multiplier\".\n# Denoting D == x.shape[1] == y.shape[1] the size of the feature space, rules are : \n#   - if \"gamma\" is a vector    (gamma.shape = [K]),   it is seen as a fixed parameter\n#   - if \"gamma\" is a 2d-tensor (gamma.shape = [M,K]), it is seen as a \"j\"-variable \"gamma_j\"\n#\n#   - if K == 1 , gamma is a scalar factor in front of a simple euclidean squared norm :\n#                 WeightedSquareNorm( g, x-y ) = g * |x-y|^2\n\n#   - if K == D , gamma is a diagonal matrix:\n#                 WeightedSquareNorm( g, x-y ) = < x-y, diag(g) * (x-y) >\n#                                              = \\sum_d  ( g[d] * ((x-y)[d])**2 )\n#   - if K == D*D, gamma is a (symmetric) matrix:\n#                 WeightedSquareNorm( g, x-y ) = < x-y, g * (x-y) >\n#                                              = \\sum_{k,l}  ( g[k,l] * (x-y)[k]*(x-y)[l] )\n#\n# N.B.: Beware of Shape([D]) != Shape([1,D]) confusions !\n\n# Isotropic, uniform kernel -----------------------------------------------------------\nsigma = torch.tensor( [0.1] ).type(dtype)\nparams[\"gamma\"] = 1./sigma**2\nshowcase_params(params, \"Isotropic Uniform kernel\", 1)\n\n# Isotropic, Variable kernel ----------------------------------------------------------\nsigma = torch.tensor( [ \n    [0.15], \n    [0.07], \n    [0.3] \n    ]).type(dtype)\nparams[\"gamma\"] = 1./sigma**2\nshowcase_params(params, \"Isotropic Variable kernel\", 4)\n\n# Diagonal, Uniform kernel ---------------------------------------------------------\nsigma = torch.tensor( [0.2, 0.1] ).type(dtype)\nparams[\"gamma\"] = 1./sigma**2\nshowcase_params(params, \"Diagonal Uniform kernel\", 2)\n\n# Diagonal, Variable kernel --------------------------------------------------------\nsigma = torch.tensor( [ \n    [0.2, 0.1], \n    [.05, .15], \n    [.2,  .2] \n    ] ).type(dtype)\nparams[\"gamma\"] = 1./sigma**2\nshowcase_params(params, \"Diagonal Variable kernel\", 5)\n\n# Fully-Anisotropic, Uniform kernel ---------------------------------------------------\nSigma = torch.tensor( [1/0.2**2, 1/.25**2, 1/.25**2, 1/0.1**2 ] ).type(dtype)\nparams[\"gamma\"]   = Sigma\n#params[\"backend\"] = \"pytorch\"\nshowcase_params(params, \"Fully-Anisotropic Uniform kernel\", 3)\n\n# Fully-Anisotropic, Variable kernel --------------------------------------------------\nSigma = torch.tensor( [ \n    [1/0.2**2, 1/.25**2, 1/.25**2, 1/0.1**2  ] ,\n    [1/0.1**2,     0,       0,     1/0.12**2 ] ,\n    [1/0.3**2,-1/.25**2,-1/.25**2, 1/0.12**2 ] ,\n    ] ).type(dtype)\nparams[\"gamma\"] = Sigma\nshowcase_params(params, \"Fully-Anisotropic Variable kernel\", 6)\n\nplt.gcf().set_size_inches(18,12)\n\nimport os\nfname = \"output/anisotropic_kernels.png\"\nos.makedirs(os.path.dirname(fname), exist_ok=True)\nplt.savefig( fname, bbox_inches='tight' )\n\n\nprint(\"Done. Close the figure to exit.\")\nplt.show(block=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}