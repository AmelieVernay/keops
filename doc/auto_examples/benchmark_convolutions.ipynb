{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nBenchmark KeOps vs pytorch on simple convolutions\n=================================================\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#import sys, os.path\n#sys.path.append(os.path.dirname(os.path.abspath(__file__)) + (os.path.sep + '..')*2)\n\nimport numpy as np\nimport time, timeit\n\nfrom pykeops.numpy.utils import np_kernel\n\n# size of the test\nM = 2000\nN = 300\nD = 3\nE = 3\n\ntype = 'float32'\n\n# declare numpy variables \nx = np.random.randn(M, D).astype(type)\ny = np.random.randn(N, D).astype(type)\nb = np.random.randn(N, E).astype(type)\nsigma = np.array([2.4]).astype(type)\n\n# declare their torch counterparts\ntry:\n    import torch\n\n    use_cuda = torch.cuda.is_available()\n    device = 'cuda' if use_cuda else 'cpu'\n    torchtype = torch.float32 if type == 'float32' else torch.float64\n\n    xc = torch.tensor(x, dtype=torchtype, device=device)\n    yc = torch.tensor(y, dtype=torchtype, device=device)\n    bc = torch.tensor(b, dtype=torchtype, device=device)\n    sigmac = torch.tensor(sigma, dtype=torchtype, device=device)\n\nexcept:\n    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Benchmark\n###########################################################\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "enable_GC = False # Garbage collection?\nGC = 'gc.enable();' if enable_GC else 'pass;'\nLOOPS = 200\nprint('Times to compute ', LOOPS, ' convolutions of size {}x{}:'.format(M, N), end='\\n')\n\nfor k in (['gaussian', 'laplacian', 'cauchy', 'inverse_multiquadric']):\n    print('----------------------------------- kernel: ' + k)\n    \n    # pure numpy\n    gnumpy =  np_kernel(x,y,sigma,kernel=k) @ b\n    speed_numpy = timeit.Timer('gnumpy = np_kernel(x,y,sigma,kernel=k) @ b',\n                               GC, globals=globals(),\n                               timer=time.time).timeit(LOOPS)\n    print('Time for Python:              {:.4f}s'.format(speed_numpy))\n\n    # keops + pytorch : generic tiled implementation (with cuda if available else uses cpu)\n    try:\n        from pykeops.torch import Kernel, kernel_product\n\n        params = {\n            'id': Kernel(k+'(x,y)'),\n            'gamma': 1. / (sigmac * sigmac),\n            'backend': 'auto',\n        }\n        g1 = kernel_product(params, xc, yc, bc,  mode='sum').cpu()\n        speed_pykeops_gen = timeit.Timer(\"g1 = kernel_product(params, xc, yc, bc, mode='sum').cpu()\",\n                                         GC, globals=globals(),\n                                         timer=time.time).timeit(LOOPS)\n        print('Time for keops generic:       {:.4f}s'.format(speed_pykeops_gen),end='')\n        print('   (absolute error:       ', np.max(np.abs(g1.data.numpy() - gnumpy)), ')')\n    except:\n        print('Time for keops generic:       Not Done')\n\n    # vanilla pytorch (with cuda if available else uses cpu)\n    try:\n        from pykeops.torch import Kernel, kernel_product\n    \n        params = {\n            'id': Kernel(k + '(x,y)'),\n            'gamma': 1. / (sigmac * sigmac),\n            'backend': 'pytorch',\n        }\n        \n        g0 = kernel_product(params, xc, yc, bc, mode='sum')\n        speed_pytorch = timeit.Timer(\"g0 = kernel_product(params, xc, yc, bc, mode='sum')\",\n                                     GC, globals=globals(),\n                                     timer=time.time).timeit(LOOPS)\n        print('Time for Pytorch:             {:.4f}s'.format(speed_pytorch),end='')\n        print('   (absolute error:       ', np.max(np.abs(g0.cpu().numpy() - gnumpy)),')')\n    except:\n        print('Time for Pytorch:             Not Done')\n\n    # specific cuda tiled implementation (if cuda is available)\n    try:\n        from pykeops.numpy import RadialKernelConv\n        my_conv = RadialKernelConv(type)\n        g2 = my_conv(x, y, b, sigma, kernel=k)\n        speed_pykeops = timeit.Timer('g2 = my_conv(x, y, b, sigma, kernel=k)',\n                                     GC, globals=globals(),\n                                     timer=time.time).timeit(LOOPS)\n        print('Time for keops cuda specific: {:.4f}s'.format(speed_pykeops), end='')\n        print('   (absolute error:       ', np.max(np.abs(g2 - gnumpy)),')')\n    except:\n        print('Time for keops cuda specific: Not Done')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}