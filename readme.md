# KErnel OPerationS for GPUs

```
          88          oooo    oooo             .oooooo.                                  88
        .8'`8.         `888   .8P'             d8P'  `Y8b                              .8'`8.
       .8'  `8.         888  d8'     .ooooo.  888      888 oo.ooooo.   .oooo.o        .8'  `8.
      .8'    `8.        88888[      d88' `88b 888      888  888' `88b d88(  "8       .8'    `8.
     .8'      `8.       888`88b.    888ooo888 888      888  888   888 `"Y88b.       .8'      `8.
    .8'        `8.      888  `88b.  888    .o `88b    d88'  888   888 o.  )88b     .8'        `8.
    88oooooooooo88     o888o  o888o `Y8bod8P'  `Y8bood8P'   888bod8P' 8""888P'     88oooooooooo88
                                                            888
                                                           o888o
```

**N.B.: This library is under development... some keys features have not been implemented yet.**

The KeOps library allows you to compute efficiently expressions of the form

```math
\gamma_i = \text{Reduction}_j \big[ f(x^1_i, x^2_i, ..., y^1_j, y^2_j, ...)  \big]
```

and their derivatives.

The basic example is the Gaussian convolution  on a non regular grid in $`\mathbb R^3`$ (aka. **RBF kernel product**). Given :

- a target point cloud $`(x_i)_{i=1}^N \in  \mathbb R^{N \times 3}`$;
- a source point cloud $`(y_j)_{j=1}^M \in  \mathbb R^{M \times 3}`$;
- a signal or vector field $`(\beta_j)_{j=1}^M \in  \mathbb R^{M \times D}`$ attached to the $`y_j`$'s

KeOps may computes $`(\gamma_i)_{i=1}^N \in  \mathbb R^{N \times D}`$ given by

```math
 \gamma_i =  \sum_j K(x_i,y_j) \beta_j,  \qquad i=1,\cdots,N
```

where $`K(x_i,y_j) = \exp(-|x_i - y_j|^2 / \sigma^2)`$.

### Usage

We provide bindings in python (both numpy and pytorch complient),  Matlab and R.

### Performances
In order to scale up on large datasets, we use a "tiled implementation" that allows us to get a $`O(n)`$ memory footprint instead of the usual $`O(n^2)`$ codes generated by high level libraries such as Thrust or cuda version of pyTorch and TensorFlow. It comes with various examples ranging from lddmm (non rigid deformations) to kernel density estimations (non parametric statistics).

 The best performances are achieved for the range $`N=1000`$ to $`N=5.10^5`$.

# Quick start

## Python user

Two steps:

1) Run the out-of-the-box working examples [`./pykeops/examples/convolution.py`](./pykeops/examples/convolution.py) and [`./pykeops/example/generic_example.py`](./pykeops/example/generic_example.py).

2) If you are already familiar with the LDDMM theory and want to get started quickly, please check the shapes toolboxes: [plmlab.math.cnrs.fr/jeanfeydy/shapes_toolbox](https://plmlab.math.cnrs.fr/jeanfeydy/shapes_toolbox) and [plmlab.math.cnrs.fr/jeanfeydy/lddmm_pytorch](https://plmlab.math.cnrs.fr/jeanfeydy/lddmm_pytorch).

## Matlab user

Two steps:

1) Compilation of the cuda codes. The subdirectory `./matlab` contains a shell script `makefile.sh`. The user needs to custom the paths contained in this file. The script produces mex files callable from any matlab script.

2) Run the out-of-the-box working examples `./matlab/example/convolution.m`

### known issues

if an error involving libstdc++.so.6 occurs like

```
cmake: /usr/local/MATLAB/R2017b/sys/os/glnxa64/libstdc++.so.6: version `CXXABI_1.3.9' not found (required by cmake)
cmake: /usr/local/MATLAB/R2017b/sys/os/glnxa64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by cmake)
cmake: /usr/local/MATLAB/R2017b/sys/os/glnxa64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /usr/lib/x86_64-linux-gnu/libjsoncpp.so.1)
```

try to load matlab with the following linking variable :

```bash
export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libstdc++.so.6;matlab
```

## R user

To do.

......
authors : [Benjamin Charlier](http://www.math.univ-montp2.fr/~charlier/), [Jean Feydy](www.math.ens.fr/~feydy/), [Joan Alexis Glaun√®s](www.mi.parisdescartes.fr/~glaunes/)
