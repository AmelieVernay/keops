This library is under development... some keys features have not been implemented yet. 

```
      88 88           oooo    oooo             .oooooo.                                88 88
     .8' `8.          `888   .8P'             d8P'  `Y8b                              .8' `8. 
    .8'   `8.          888  d8'     .ooooo.  888      888 oo.ooooo.   .oooo.o        .8'   `8.
   .8'     `8.         88888[      d88' `88b 888      888  888' `88b d88(  "8       .8'     `8.
  .8'       `8.        888`88b.    888ooo888 888      888  888   888 `"Y88b.       .8'       `8. 
 .8'         `8.       888  `88b.  888    .o `88b    d88'  888   888 o.  )88b     .8'         `8.
 88ooooooooooo88      o888o  o888o `Y8bod8P'  `Y8bood8P'   888bod8P' 8""888P'     88ooooooooooo88
                                                           888                                                      
                                                          o888o                                                     
```


KeOps is a library which implements in Cuda various operations using kernels. We also provide bindings in python (numpy and pytorch complient),  matlab and R.

It uses a "tiled implementation" in order to have a $`O(n)`$ memory footprint instead of usual $`O(n^2)`$ codes generated by high level libraries like Thrust or cuda version of pyTorch and TensorFlow. It comes with various examples ranging from lddmm (non rigid deformations) to kernel density estimations (non parametric statistics).

For instance, the basic example is a Gaussian convolution on a non regular grid in $`\mathbb R^3`$ : given two point clouds $`(x_i)_{i=1}^N \in  \mathbb R^{N \times 3}`$ and $`(y_j)_{j=1}^M \in  \mathbb R^{M \times 3}`$  and a vector field $`(\beta_j)_{j=1}^M \in  \mathbb R^{M \times 3}`$ attached to the $`y_j`$'s, KeOps may computes $`(\gamma_i)_{i=1}^N \in  \mathbb R^{N \times 3}`$ given by
```math
 \gamma_i =  \sum_j K(x_i,y_j) \beta_j,  \qquad i=1,\cdots,N
```
 where $`K(x_i,y_j) = \exp(-|x_i - y_j|^2 / \sigma^2)`$. The best performances are achieved for the range $`N=1000`$ to $`N=5.10^5`$.
 
# Quick start

## Python user

Two steps:

1) Compilation of the cuda codes. The subdirectory `./python` contains a shell script `makefile.sh`. The user needs to custom the paths contained in this file. The python wrappers use the ctypes library to produce python function callable from any python script. 

2) Run the out-of-the-box working examples `./python/example/convolution.py`

3) If you are already familiar with the LDDMM theory and want ot get started quickly, please check the all-in-one script: `python/tutorials/lddmm/lddmm_pytorch.py`

## Matlab user

Two steps:

1) Compilation of the cuda codes. The subdirectory `./matlab` contains a shell script `makefile.sh`. The user needs to custom the paths contained in this file. The script produces mex files callable from any matlab script.

2) Run the out-of-the-box working examples `./matlab/example/convolution.m`

### known issues

if an error involving libstdc++.so.6 occurs like 
```
cmake: /usr/local/MATLAB/R2017b/sys/os/glnxa64/libstdc++.so.6: version `CXXABI_1.3.9' not found (required by cmake)
cmake: /usr/local/MATLAB/R2017b/sys/os/glnxa64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by cmake)
cmake: /usr/local/MATLAB/R2017b/sys/os/glnxa64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /usr/lib/x86_64-linux-gnu/libjsoncpp.so.1)
```
try to load matlab with the following linking variable :

```bash
$ export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libstdc++.so.6;matlab
```


## R user

To do.


......
   
authors : Charlier,Feydy, Glaun√®s
